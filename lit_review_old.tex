

\section{Literature Review}


Throughout the literature review, we will develop the consistant notation and technology in order to fully frame the problem and work towards improving the system.
perhaps include some important figures from others work to explain concept

\subsection{Modeling Cascading Power Failures}

Try to find simpliest model of cascading power failures that captures the important effects of the process


\subsubsection{Topologic Model}

describe grid in terms of graph
edges (arcs) represent transmission lines and specific devices
nodes - bus - (represent interconnection point)

what this lacks dependence on loading


Models with topological and operating strucutre
\subsubsection{OPA Model}
Dobson papers
Two  characteristics, two types

hines et al  points out flaws in topological only models

Topological with flow estimates

Deterministic
Albert et al (2004) - Structural Vulnerability of the Norht American power grid 
-- cursory overview of various heuristical type procedures on topology of power grid
Crucittie et al (2004) - Model for cascading failures in complex networks

Zhao et al (2004) - Attack vulnerability of scale-free networks due to cascading breakdown
Kinney et al (2005) - Modeling cascading failures in the North American power grid
Wang and Rong (2009) Casacade-based attack vulnerability on the US power grid
Duenas-Osorio and Vemuru (2009) Cascading failures in complex infrastructure systems
Buldyrev et al (2009) Catastrophic cascade of failures in interdependent networks


Load based models
Deterministic
Bush (2005) Critical infrastructure protection decission support system project overview
-Critical Infrastructure Protection Decision Support System (CIP/DSS)

Critical Infrastructure Modeling System (CIMS) Idaho National Lab 2005
-What if (Dudenhoeffer et al (2006) - CIMS: a framework for infrastructure interdependency modeling and analysis

Ni et al (2003) Online risk-based security assessment
Zima and Andersson (2004) Wide area monitoring and control as a tool for mitigation of cascading failures


Probalistic
Liao et al (2004) Phase transitions in probability of cascading failures
Mili et al (2004) Risk assessment of catastrophic failures in electric power systems
Chen et al (2005) Cascading dynamics and mitigation assessment in power system disturbances via a hidden failure model
Dobson et al 
(2001)  An initial model for complex dynamics in electric power system blackouts
(2004) Complex dynamics of blackouts in power transmission systems
(2007)Complex systems analysis of series of blackouts: Cascading failures, critical points, and self-organization
 (2011) Exploring complex system aspects of blackout risk and mitigation
Anghel et al (2007) Stochastic model for power grid dynamics
Bienstock (2011)

UNCAT
[21] D. S. Kirschen, D. Jawayeera, D. P. Nedic, and R. N. Allan, “A probabilistic
indicator of system stress,” IEEE Trans. Power Syst., vol. 19,
no. 3, pp. 1650–1657, Aug. 2004.
[22] D. P. Nedic, I. Dobson,D. S.Kirschen, B.A. Carreras, andV. E. Lynch,
“Criticality in a cascading failure blackout model,” Elect. Power Energy
Syst., vol. 28, pp. 627–633, Mar. 2006.
[23] M. Anghel, K. A. Werley, and A. E. Mottor, “Stochastic model for
power grid dynamics,” in Proc.


HIDDEN FAILURES
[11] A. G. Phadke and J. S. Thorp, “Expose hidden failures to prevent cascading
outages,” IEEE Comput. Appl. Power, vol. 9, pp. 20–23, 1996.
[12] S. Tamaronglak, “Analysis of power system disturbances due to relay
hidden failures,” Ph.D. dissertation, Virginia Polytechnic and State
Univ., Blacksburg, VA, 1994.
[13] J. Chen, J. S. Thorp, and I. Dobson, “Cascading dynamics and mitigation
assessment in power system disturbances via a hidden failure
model,” Int. J. Elect. Power Energy Syst., vol. 27, pp. 318–326, May
2005.
11 J. Chen and J. S. Thorp, ‘‘A reliability study of transmission system protection
via a hidden failure DC load flow model,’’ IEEE Fifth International
Conference on Power System Management and Control, 17–19 April
2002, pp. 384–389.

%%
in some sense, the transition from a unstable, unfeasibil solution to next point is some type of min energy path, or lower point of potential well.  << Lyapanuv functions!!
%%


On topological models
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Hines et al (2010) Do topological models provide good information about electricity infrastructure vulnerability  
Cotilla-Sanchez (2012) Comparing the topological and Electrical Structure of the North American Electric Power Infrastructure \cite{cotilla_2012}

Power Law Failure
from hines (15)
Degree Distribution
from hines different countries/regions different topo structure
exponential (16-18) small-world networks
power-law (2,19)
scale-free networks (17,26,34) (strongly heterogenous (power-law) node connectivity) uniquely robust to random failures but vulnerabe to directed attacks)
builds on (22)
Eastern Interconnect - 41228 Vertices 52075 links, average degree,k, 2.53
Western Interconnect 11432 verticies 13734 links, average degree,k, 2.4
Texas Interconnect 4513, 5532, k =2.45
statistical measures for graphs
degree distribution (2)
characteristic path length (3)
graph diameter (36)
clustering coefficient (3)
degree assortativty (2)

$ G = \left\{ N, M \right\}$
Adjancency matrix $A$, elements $a_{ij} = 1$ if connected.
Distance Matrix $D$

Topological distances
degree of $i$ is $k_i = \sum_i^n a_{ij}$
diameter $d_{max} = \max_{ij} d_{ij}$
characteristic path length $L = \frac{1}{n,n-1} \sum_{ij | i \neq j} d_ij$
average nodal distance $d_i = \sum_{j=1}^n \frac{d_ij}{n-1}$

clustering coefficient (3)
$ C = \frac{1}{n} \sum_{i=1}^n c_i$
$c_i = \frac{e_i}{(k_i(k_i - 1))/2}$, $e_i$ is number of links within clust of nodes, including i and neighbors $N_i$
$e_i = \sum_{\forall j,k \in \left\{ N_i \cup i \right\}} a_{jk}/2$

degree assortativity (r) (37)
extent nodes connect to nodes with similar degree connectivity

Topological results
Power networks do not have same degree distribution as same sized synthetic network
North american power networks degree distributions do not follow power law. Scale free networks fit well with power law.  Power networks are not scale-free in topological structure.  (follow exponetial)
Power networks lie between a regular grid, in which $L$ scales linearly with $n$ or $\sqrt{n}$, and small world, $L$ scales with $\ln{n}$
Power networks had a fairly high degree of clustering, may be long distance lines difficult
Negative associative, substation buses with large number of radial connections (distribution feeders)

Electrical structure
Data about topological structure are not sufficient to describe the performance of power networks (24)
connectivity between components
-Sensitivity matrix
--Power transfer distribution factor matricies(41)
-Electrical distances (42) - earliest work
Lagonotte (1989) Structural analysis of the electrical system: Application to secondary voltage control in france
--application to reliability and economic power system problems (43-46)
Lu (1995) A new formulation of generator penalty factors
Hang (2000) A fast voltage security assessment method using adaptive bounding
Zhong (2004) Localized reactive power markets using the concept of voltage control areas
Hines (2008) A centrality measure for electrical networks
Wang (2010) Electrical centrallity measures for electric power grid vulnerability analysis

-Voltage phase angles between areas as measure of stress in power networks (47)
Power Flow Jacobian matricies
$ \Delta P = \frac{ \partial P }{ \partial \theta} \Delta \theta + \frac{ \partial P }{ \partial | V | } \Delta | V |$
assume voltages held constant
$\frac{ \partial P }{ \partial \theta} $ is a Laplacian matrix
Set $G = \frac{ \partial P }{ \partial \theta} $
$e(a,b) = g_{a,a}^{-1} + g_{b,b}^{-1} - g_{a,b}^{-1} - g_{b,a}^{-1}$
$E$ satisfies properties of distance matrix under dc power flow assumption, and empiraclly held otherwise
analogus to node degree
$e_a = \sum_{b=1}^n \frac{e_{ab}}{n-1}$
$c_a = e_a^{-1}$ centrality

topological distances have exponential tail, electrical distances have power-law tails
weak correlation between two types of distances
picture of electric centrality seem to point out very well importance of each node to grid stability
$E$ is weighted and fully connected $n(n-1)$ links
$R$ with $r_{ab} = 1 $ if $e_{ab} < t$, with $t $ adjusted to produce $m$ links
$R$ has lots of nodes with no connection, with the interpretation that few nodes have disproportionate influence on a large portion of the nework

MAY BE ABLE TO USE THIS TO FIND AREAS TO IMPROVE THE NETWORK!!!!!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Hines (2011) Topological Models and Critical slowing down: Two approaches to Power System blackout risk analysis
Disturbances
10 August 1996 Western Interconnect
14 August 2003 North America (1)
4 November 2006 Europe (2)
10 November 2009 South America (3)

Large blackout contribute disproportionaly (4, 5,19)
Risk from vulnerable components (protect components)
risk from operating states close to dynamic instability (avoid these operating states)

Wang (14) and Albert (9) draw different conclusions using similar data

Ohm and Kirchoff law not captured well in simple topological models
relationship between physical properties and topo metrics (17,18,10) sometimes correlate to performance

GOAL: Compare vulnerability conclusions from topo measure of vulnerability with more realistic model of power network failure

QUOTE: The third measure, which does not appear in the
existing network science literature, is blackout sizes as
calculated from a model of cascading failure in a power
system. While a perfect model of cascading failure
would accurately represent the continuous dynamics
of rotating machines, the discrete dynamics associated
with relays that disconnect stressed components from
the network, the non-linear algebraic equations that
govern flows in the network, and the social dynamics
of operators working to mitigate the effects of system
stress, all power system models simplify these
dynamics to some extent. Unlike simple topological
metrics, our model does capture the effects of Ohm’s
and Kirchhoff’s laws, by using linear approximations
of the non-linear power flow equations [23]. Similar
models have been used to study cascading failure in a
number of recent papers [4], [19], [24].

USed cascading simulation to compare results to some common topological models.  The topo models appear to have erroneous results


Critical slowing down - half of paper, may be interesting to write some up for more depth of generator dynamics


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


  Similar papers have used similar model (4) (19) (24)  (OPA, IMPROVED OPA)


Now that we see that we need a more detailed model than just topological, we will introduce power flows on the grid that obey the laws of physics.  This can be seen in OPA, and then in extensions of the model ('improved opa' , i like callling extensions)

Now go in depth on the initial opa model and ways to add some complexity and details to it.  however it is always a balance of how much resources you have to solve problem and amount of resolution you need.  typically easy in beginning but gets increasingly complex to find ever improving resolution.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The ORNL-PSerc-Alask (OPA) model    
Oak Ridge National Laboratory, Power System Engineering Research Center of Wisconsin University, Alaska University
Dobson et. al (2001) \cite{dobson_2001}

self-organized criticality.  two dynamics forces on seperate time scales
slow time scale is between load growth and growth in system capacity
fast time scale is cascading line overloads and outages
--outages lead to increased system capacity

correlation and probability distribution suggest power system dynamics consistant with self-organized criticality (4,5)
slow constant load growth reduce margins on lines, increasing failure risk
engineering response to blackout in operating policies, maintenance, equipment or controls, increase margins

model represents the processes in greatly simplified form

SLOW TIME SCALE
daily load growth, peak load used to represent
$P_{ik}$ real power injected at bus $i$ on day $k$
$F_{jk} $ real power flowing on line $j$ on day $k$
Linearized power flow model
$F_k = A P_k$, where $A$ is from network 
$P_k = P_0 \prod_{l=1}^k \lambda_l $ where $\lambda_l $ is a continues random variable i.i.d. bounded in $[\lambda_{min},\lambda_{max}]$, with some mean slightly larger than 1.
Fractional overload $M_{jk} = \frac{F_{jk}}{F_{jk}^{max}}$
If line is overloaded on a day, $F_{k+1}^{max} = \mu_k F_{jk}^{max}$ where $\mu$ is iid and bounded again
Generator capacity grow at average load growth rate

FAST TIME SCALE
initiating random line outages based on overload $M$, pdf $h^0$
outages of overloaded lines, $M$, pdf $h^1$
when line is outaged, system is redispatched
redispatch function is to minimize change in generators and 100 weight on load shedding
end if no line outages
goal of this model is to produce list of lines that could plausibly be involved in cascading event.
model does not seek to reproduce any details of cascade

BOTH TOGETHER
the system goes towards an equalibrium in dynamical or statistical sense  (time average pattern goes towards some limit point)
slow dynamics can be thought of in Markov sense

Starting point for future research

Carreras and Lynch et al (2002) \cite{carreras_2002}
chaos

%%%%
Carreras et. al (2004)  Evidence for Self-Organized Criticality in a Time Series of Electric Power System Blackouts \cite{carreras_2004}
%%%%
Average frequency of blackouts in US is 13days, frequency has not changed in 30 years
probability distribution of blackoout size has power tail (exponent $-1.3 \pm .2$), large blackout probability is relatively, and have higher societal cost, even though they are less frequent then small ones

Power transmission system considering engineering and physical aspects, as well as economic, regulatory, and political responsed to balckouts and increases in load.
here is simpliefied model which reproduces some of the main features of North American Blackout data

individual blackouts triggered by random events (equipment failure, weather, vandalism, attack), but become widespread through a series of cascades.  There are critical points with maximum power flow through the newtwork and self-organization which maximizes efficiency and regulates reliability requipments, may lead these power system to self-organizes criticality.

related work( chen and thorp (11,12)) (hidden failures)

slow dynamics 
1. growth of demand
-grows $P_{t+1} = \lambda P_t$
-randomized local fluctuations daily
2. response to balckouts by upgrades to transmission
-grows $F_{t+1} = \mu F_t$ if line fails
3. response to increased demand by increase generator power
-quantized power growth
-related to line capacity in neighborhood
- mean power generation reeaches a threshold

-generator capability margin used to deal with daily fluctuations in demand

two types of critical points.
limiting power flows due to tranmission lines   (larger blackouts less frequently, multiple lines tripping)
limiting power flows due to generation capacity  (frequent blackouts of smaller size)


when these are close, black out size has power law
away from these points, they dont
but also the maximum power delivierd for the system appears to be when these two points balance


CANT STUDY larges blackouts by looking at initial triggering events, must look at root cause, deeper, long-term forces that drive evolution of power system.

%
Dobson et al (2007) Complex systems analysis of series of blackouts: Cascading failure, critical points, and self-organization \cite{dobson_2007}
%

, use dobsons papers on comparing blackout tails

%%%%
%Dobson et. al (2009)  Complex sytems analysis of series of blackouts: cascading failure, critical points, and self-organization
%%%%






[14] I. Dobson, B. A. Carreras, V. E. Lynch, and D. E. Newman, “An initial
model for complex dynamics in electric power system blackouts,” in
Proc. 34th Hawaii Int. Conf. System Sciences, Maui,HI, Jan. 2001, pp.
710–718.
[15] B. A. Carreras,V. E. Lynch, I. Dobson, andD. E.Newman, “Dynamics,
criticality and self-organization in a model for blackout in power transmission
systems,” in Proc. 35th Hawaii Int. Conf. System Sciences, Big
Island, HI, Jan. 2002.
[16] B. A. Carreras, V. E. Lynch, I. Dobson, and D. E. Newman, “Complex
dynamics of blackouts in power transmission systems,” Chaos, vol. 14,
pp. 643–652, Sep. 2004.
[17] H. Ren, I. Dobson, and B. A. Carreras, “Long-term effect of the n-1
criterion on cascading line outages in an evolving power transmission
grid,” IEEE Trans. Power Syst., vol. 23, no. 3, pp. 1217–1225, Aug.
2008
[18] B. A. Carreras, D. E. Newman, I. Dobson, and N. S. Degala, “Validating
OPA with WECC data,” in Proc. 46th Hawaii Int. Conf. System
Sciences, Wailea, HI, Jan. 2013.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
S. Mei (2009)  An improved opa model and blackout risk assessment \cite{mei_2009}

Blackout distribution not enough.  
Two laylers, 
fast dynamics of the system - 

[19] S. Mei, F. He, X. Zhang, S. Wu, and G. Wang, “An improved OPA
model and blackout risk assessment,” IEEE Trans. Power Syst., vol.
24, no. 2, pp. 814–823, May 2009.

Qi (2013) Blackout Model Considering Slow Process  \cite{qi_2013}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% 
Beinstock et al. modification to OPA

smoothing function



%%%%


%%%%%%
My hypothesis on how this literature developed, following 2003, large push to understand large scale cascading power failures due to large negative impact on society.  Easiest way to analyze is through the basic topological structure.  The following years saw large amount of papers on topo models to find vulnerabilities.  As these view progressed, realized that topo models had inhearant flaws, exposed by Hines et al. in favor of more realistic flow based models.  During this same time computationale power has increased to point can make use of these more detailed models to find vulnerabilities in this system.  

Perhaps simple paper count of topo models over time from 2000-2012 to show dramatic spike in 2004 and the fall off as the weakness of the models were shown, even though these cascading events keep happening

GOAL: use more realistic model of cascading power failures along with strong computational resources and sold algorithmic development in the computer science and operation research community to solve design problems in the power system arena that address cascading power failure vulnerability


IF Can make connection between LMP and cascades, can use this as motivations for many things
-Electric vehicle, real time pricing
--MAJOR CONCERN FOR FUTURE
--LARGE DELTA ON GRID relative to regular growth patters )  could show contrast to OPA -, it will grow load disportionaly in spots
--THIS WILL MAKE RISK OF CASCADES WORSE
-ECONOMIC MODEL BASED ON VOLATILITY  -- VOLATILITY IS HARMFUL TO SSYSTEM  -- VARIANCE COSTS MONEY, instead we produce at AVERAGE RATE and sell ability to DEVIATE or buy capacity in order to protect UNCERTAINTY IN SYSTEM

-COINCIDENTALLY ?!?!?! the same thing that will put pressure on the grid can help to arbitrage price differentials.  and if large price differtials can make cascades more likely, we WANT THIS BADLY
%%%%%%%%%%%%%%%%%




Vulnerability analysis
Wang (2009) Cascade-based attack vulnerabilities on the US power grid
Bompard (2009) Analysis of structural vulnerabilities in power transmission grids
Arianos (2009) Power grids vulnerabiliites in power transmission grids
Blumsack (2007) a quantitative analysis of the relationship between congestion and reliability in electric power networks


Phase Transition, Lyapunuv
16 C. L. DeMarco, ‘‘A phase transition model for cascading network failure,’’
IEEE Control Syst. Mag. 21, 40–51 ~2001!.


\subsubsection{Power Flow}
Power System Analysis and Design Book \cite{glover_2008}
Stott (2009) DC power flow revisisted \cite{stott_2009}

\subsubsection{Economic Dispatch}


\subsubsection{Design Problems}
Transmission Expansion
Pozo 2013 A Three-Level Static MILP Model for Generation and Transmission Expansion Planning
Allocating Reserves

[32] J. Cui and J. Chen, Design and Building of Overhead Lines. Beijing,
China: China WaterPower Press, 2011.
[29] S. Guo, Basics of Design of Overhead Transmission Lines. Beijing,
China: China Electric Power Press, 2009.

[24] P. Simpson and R. Van Bossuyt, “Tree—Caused electric outages,” J.
Arboricult., vol. 22, pp. 117–121, May 1996.
[25] D. T. Radmer, P. A. Kuntz, R. D. Christie, S. S. Venkata, and R.
H. Fletcher, “Predicting vegetation-related failure rates for overhead
distribution feeders,” IEEE Trans. Power Del., vol. 17, no. 4, pp.
1170–1175, Oct. 2002.
[26] S. D. Guikema, R. A. Davidson, and H. Liu, “Statistical models of the
effects of tree trimming on power system outages,” IEEE Trans. Power
Del., vol. 21, no. 3, pp. 1549–1557, Jul. 2006.
[27] S. R. Cieslewicz and R. R. Novembri, Utility Vegetation Management
Final Report, CN Utility, LLC, 2004.
[28] H. I. Anis, “Probabilistic modeling of power lines magnetic fields,” in
Proc. IEEE Power Engineering



\subsection{Optimization Tools}
Want to do design problems on power grids.  Optimize these models. 

what characteristics does this model have

not convex, not continuously differentiable, noisy 

need robust solution methodology 


stochastic vs deterministic

stochastic 
-simulation based
Berry Nelson

stochastic
-opt community
Guanghai Lan, 
Sample Approximation Average
Random Gradient Descent
Robust Stochastic Approximation Nemirouski Jouditsty Lan Shapiro
Adaptive Robust Optimization for security constrained unit commitment Bertsimas Lituinov Sun Zhao Zheng
Introduction to stochastic search and optimization Spall

deterministic
-pattern search
Generating Set Search (Kolda, Lewis, Torczon Review 2003 convergence results)
derivative free optimization book (Conn Scheinberg Vicente 2003)
Simplex

deterministic
-model based (Conn Scheinberg Vicente 2003) for all of these
interpolation
regression
trust regions


derivative free optimization
derivate used - could give examples of it not working <<< more mork
local model based




\subsubsection{Derivative Free Optimization}
--pattern search, using secondary simulation data, model based?, evolutionary, trust regions
Direct Search Methods: then and now ( Lewis, Torczon, Trosset ) \cite{lewis_2000}

\begin{equation}
\min_{ f: \R{n} \rightarrow \R{}} f(x)
\end{equation}
f continuously differentiable but unavailable

pattern search methods
simplex method (geometry based search strategies)
adaptive sets of search directions

some history on convergence results

Polak '71 specific algorithm converge to accumlation point $x'$ of $\left\{x_k\right\}$ such tthat 
\begin{equation}
\bigtriangledown f(x') = 0
\end{equation}

Berman provides results for fairly general algorithm based on lattice method

initialize 
$x_0, \Delta_0$
\begin{equation}
L(x_0, \Delta_0) = \left\{ x | x = x_0 + \Delta_0 \lambda, \lambda \in \Lambda \right\}
\end{equation}
where $\Lambda $ is a lattice of integral points on $\R{n}$
if $L_k  = L(x_k, \Delta_k)$, $\Delta_k = \frac{\delta_0}{\tau^k}$, $\tau > 1$ and $L_k \subset L_{k+1}$
as $k \uparrow$ , $\Delta \downarrow$, as $k$ increases, resolution increases

Cea gives convergence results on Hookes and Jeeves algorithm, for strictly convex function, you get a unique minimizer

V. Torczon generalizes Bermans results
patterns of form 
\begin{equation}
x_k' = x_k + \Delta_k B \gamma_k'
%%%x_k^' = x_k + \Delta_k \Beta \gamma_k^'
\end{equation}
where $B$ is a nonsingular matrix and $\gamma_k'$ is an integral vector
Assume that $L(x_0) = \left\{ x | f(x)  \le f(x_0) \right\} $ is compact, f cont. diff. on neighborhood of $L(x_0)$.  Then sequance of iterats $\left\{ x_k \right\}$ produced by algorithm has
\begin{equation}
\lim_{k \rightarrow \infty} \inf || \bigtriangledown f (x_k) || = 0
\end{equation}


Nelder Mead, expansion, contraction, reflection
Adaptive set of search direction ( Rosenbrock Powell)

%%%%%%%%%%%%%%%%%
Optimization by Direct Search: New Perspectives on Some Classical and Modern Methods (Kolda, Lewis, Torczon) \cite{kolda_2003}


search methods due to stochastic error 6,173,260
$f\in C^1$ - derivative is continuously differntiable, gradient method
$f \in C^2$ - twice differentiable, Newton based methods 69, 192, 197

direct search methods, noisy numerical error
issues
-slow asymptotic convergence
-problem size

derivative free 71,74, 177
-models via least squares, regression 121
-interpolation models 72, 74, 220
-no explicit model 115, 173, 174, 175

Direct Search - sequential examination of trial solutions involving comparison of trial solutions with the "best" obtained up to that time together with a strategy for determing next trial solutions (as a function of earlier results)

assume order relation
$ x \prec y$ if $f(x) < f(y)$
only finite amt of new iterates and can be enumerated

parallel implementation 93, 115, 140, 256
-load balancing 140
161,162

Hybrid approach
direct search with
-trust region 141
-evolutionary alg 131,132,133
-modeling acceleration technique 30, 31, 91, 100, 261

Smooth Unconstrained Minimization

Line search
if $f$ differntiable at $x$, $d$ is a descent direction for $f$ at $x$ 
\begin{equation}
- \grad f(x)^T d > 0
\end{equation}
and if $d$ is descent, $\alpha >0$ and sufficiently small, $x_t$ reduces value of $f$
\begin{equation}
f(x + \alpha d) = f(x) + \alpha \grad f(x)^T d + \mbox{o}(\alpha)
\end{equation}
with positive spanning set $k>0$
gaureented descent direction
for coordinate search $\kappa (G) = \frac{1}{\sqrt{n}}$
-bound $\kappa (G)$ for convergence result

Kolda Lewis Torczon (review) 2003
convergence analysis, continuously differentiable
$\bigtriangledown f$ lipschitz continuous

-geometry, positively spanning sets
(constrained case for feasible cones)

-cosine measure ( angle between steepest descent and search direction )
\begin{equation}
\kappa (G) = \min_{v \in \R{n}}   \max_{d \in G}   \frac{v^T d}{||v|| ||d||}
\end{equation}
want good search direction and
\begin{equation}
\lim \Delta_k \rightarrow 0
\end{equation}
--sufficient decrease (forcing function)
-- rational lattice ( lie on a grid)
-- moving grids (re orient grid based on previous info)

\begin{equation}
|| \grad f (x_k) || \le \kappa (G_k)^{-1} \left[ M \Delta_k \beta_{min} + \frac{\rho (\Delta_k)}{\Delta_k \beta_{min}}\right]
\end{equation}
why $\Delta_k$ is good termination criteria, the gradient is directly related

using curvature, positive definite $B_k$
\begin{equation}
d_k = - B_k^{-1} \grad f (x_k)
\end{equation}
newtons method gives
\begin{equation}
B_k = \grad^2 f(x_k)
\end{equation}
quasi-Newton just uses approximation to Hessian $\grad^2 f(x_k)$

simple decrease $f (x_{k+1} ) < f(x_k)$ is not enough to ensure convergence to stationary point
problems step length and descent direction

on Step Length, sufficient decrease Armijo 9,192, Goldstein 125, 197
\begin{align}
f(x_k + \alpha_k d_k) \le f(x_k) + c_1 \alpha_k \grad f(x_k)^T d_k  \label{step_length_1}\\
\grad f (x_k + \alpha_k d_k)^T d_k \ge c_2 \grad f(x_k)^T d_k \label{step_length_2}
\end{align}
with $0 < c_1 < c_2 < 1$
poor descent direction
\begin{equation}\label{descent_direction}
\frac{-\grad f(x_k)^T d_k}{|| \grad f (x_k) || ||d_k|| } \ge c > 0
\end{equation}


global convergence for line search
$f: \R{n} \rightarrow \R{}$,$f \in C^1$, $\grad f$ lipschit cont. with constant $M$

if $\left\{x_k\right\}$ satisfies \ref{step_length_1} \ref{step_length_2} \ref{descent_direction}
then $\lim_{k\rightarrow \infty } || \grad f(x) || = 0$

Generating Set Search
includes Torczon 257, Hookes and Jeeves 139 Multidirection 256, EVOP Box 35, Lewis Torczon 166, Coope Price 76,77 Yu 278 Lucidi Sciandrun 174 Garcia - Polomers Rodriquez 115,     (5, 13)

\begin{description}
\item[$D_k$] search direction, contains generating set $G_k$ for $\R{n}$, $H_k$ additional search direction, 
cosine measure $\kappa (G_k)$ has $\kappa_{min}$
\item[$\Delta_k$] contains parameters, $\phi_k$ expansion $\ge 1$, $\theta_k $ constracion $\in (0,1)$
\item[$\rho ( \dot )$] forcing function to ensure sufficient decrease $\rho : \left[ 0 , + \infty \right] \rightarrow \R{}$ with $\rho(t)$ decreasing as $t \rightarrow 0$, $\rho \equiv 0$ acceptable, $\frac{\rho (t)}{t} \rightarrow 0 $ as $t\rightarrow 0$ 
\end{description}

$\beta_{min}, \beta_{max}$
with $\beta_{min} \le ||d|| \le \beta_{max} $ for $\forall d \in G_k$ and $\beta_{min} \le || d ||$ for $\forall d \in H_k$

Updates
\begin{equation}
x_{k+1} = \left\{  \begin{array}{l l}
						x_k + \Delta_k d_k  	&	k \in \cS \\
						x_k					&	k \in \cU 
					\end{array}
			\right.
\end{equation}


\begin{equation}
\Delta_{k+1} = \left\{  \begin{array}{l l}
						\phi_k \Delta_k  		&	k \in \cS \\
						\theta_k \Delta_k	&	k \in \cU 
					\end{array}
			\right.
\end{equation}

Decrease condition
\begin{equation}
f(x_k  + \Delta_k d_k ) < f(x_k) - \rho ( \Delta_k))
\end{equation}

Generating Sets
$G = \left\{ d^{(1)} , ... , d^{(p)} \right\}$, with $p \ge n+1$ vectors in $\R{n}$
$G$ generates $\R{n}$ if for any $v\in \R{n}$, $\exists \lambda^{(1)}, ..., \lambda^{(p)} \ge 0$ such that
\begin{equation}
v = \sum_{i=1}^p \lambda^{(i)} d^{(i)}
\end{equation}

equivalently
$G$ generators $\R{n}$ iff $\exists d \in G$ such that $v^T d > 0$, that is there must be a descent direction, as long as $G$ is a positive spanning set.
The worst case angle from descent direction 
\begin{equation}
\kappa (G) = \min_{v \in \R{n}} \max_{d\in G} \frac{v^T d}{||v|| ||d||}
\end{equation}
$\kappa (G) > 0 $ implies $G$ is a generating set

which says $\exists d \in G$ such that
\begin{equation}
\kappa (G) || \grad f(x) || || d || \le - \grad f(x)^T d
\end{equation}

For convergence, need $\kappa (G_k) \ge \kappa_{min}$ for all $k$
coordinate directions, $D_{\oplus}$, gives $\kappa (D_\oplus ) = \frac{1}{\sqrt{n}}$


For convergences, need subsequence of unsuccessful iterates to have
\begin{equation}
\lim_{k \rightarrow + \infty} \Delta_k = 0
\end{equation}
with $k \in K \subset \cU$

Three ways to accomplish
\begin{description}
\item[sufficient decrease] Yu 278, Lucidi Sciandrone 174, Garcia Polomeros Rodriques 115
\item[rational latticies] Berman 21, 22 Cea 56 Polak 211 Torczon 257, Lewis Torczon 166
\item[moving grids] Coope and Price 77, Rosenbrock 227, Powell 213, Nelder Mead 194, (76,77,224)
\end{description}
need compact level sets?.?.?

Many Options for generating sets
$G_k \neq D_\oplus$ - 77,78,115,140,166,174,256
Simplex 164, not GSS, one search decreasing with only simple decrease

Model based direct search 71,72,74,177,220,221

explatory moves
pattern step
\begin{equation}
x_p = x_k + (x_k - x_{k-1})
\end{equation}
keep moving in same direction

without continuous differentiability, HARD TO PROVE MUCH
linearly constrained case $ Ax \le b$


%%%%%%%%%%%%%%%


Model Based
Simplex Based  


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Derivative Free Optimization  (Conn, Scheinberg, Vicente) 2009  \cite{conn_2009}

analysis of variance (statistical test 203)

heuristics
simulated annealing 143
genetic, evolutionary 108 129
artifical neural network 122
particle swarm 142

coordinate search 70
Nelder Mead 177
simplex gradient 141
trust region models
interpolation, regression

Ferris Deng 92
Powell 183 conjugate directions
-Zangwill 237 modification
Toint Calliers 215
Rossenbrock 201
Frimannslund Steignberg 100 rotating directions
Custodio Vicente 70 order polling directions


solve
\begin{equation}
\min_{x \in \R{n}} f(x) 
\end{equation}
do not confuse this $f$, which represents a function from $\R{n} \rightarrow \R{}$, with the $f_{ijn}$ that represents the amount of power flowing on a branch

for our cascading model, all we require is the model to return a scalar which represents some measure of risk or cost of the blackout for a given state and be able to list potential lines in the events $h(x)$, we use probabilities with h values to find sequances and covariances which give you good information

MANY WAYS TO SOLVE
model based -polynomial -underdetermined -overdetermined
pattern search - conform to local curvature
line search
simplex gradient
simple with enforcing geometry -normalized volume
simplex hessians
trust region - cauchy step
conn scheinberg toint 59, 61	interpolation, trust region
surrogate functions


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Simulation Based Optimization
Surrogate Models??? Stochastic Krigin


Simulation Versions
%%%%%%%%
Berry Nelson papers

\subsubsection{Optimization via Simulation}


L. Jeff Hong
Barry L. Nelson
Proceedings of the 2009 Winter Simulation Conference
A Breif Introduction to Optimization Via Simulation (OvS) \cite{hong_2009}

three types
R\&S
continuous OvS
discrete OvS

build models to design and analyze complex systems.
easy to change parameters and run what-if
find parameters that optimize system performance

\begin{equation}
\min g(x) = \Expect \left[ Y(x) \right] 	\hspace{20px} x \in \Theta \subset \R{d}
\end{equation}
$x$ is decision variable, simulation slow, only estimate of $g(x)$.  distrubtion vary over feasible region.  little known about properties of impled objective function (convexity, differentiability)
Recent comprehensive view Fu (2002)

Differences in feasibility structure of $\Theta$
\begin{itemize}
\item Ranking and Selecetion (R\&S) - $\Theta$ has small number of solution (less than 100), numerical or categorical, simulate all at select best
\item continuous OvS (COvS) -$x$ is continuous decision variable
\item discrete OvS - $x$ is discrete and integer ordered
\end{itemize}
not exhaustive but covers most problems in practice and research

academic algorithms often focus on provable properties, such as statistical claims on R\&S and convergence properties on COvS and DOvS.  in practice, Algorithms without convergence gaureentees but with good empirical performance

most commercial OvS implement robust metaheuristics
AutoStat - evolution strategies
OptQuest - scatter search, tabu search, neural networks
SimRunner2 - evolution strategies and genetic algorithms (Law 2007)

often robust and perform well on deterministic problems
lack sophisticated schemes to handle randomness in simulation outputs
misled by noise in simulation and report solutions with poor qualities


Ranking and Selection 

frequentist approach
Bayesian approach - optimal computing budget allocation (OCBA), Chen et al (2000) allocated simulation budget to maximize posterior probability of correct solution
	-expected value of information (EVI) Chick and Inoue (2001) minimize expected opportunity cost of the chosen solution

Bayesian approach has strategies to optimally allocating simulation effort to the solutions being considered

Suppose $k \ge 2$ solutions in $\Theta$, $x_1, ... x_k$.  $Y_j (x_i)$ is $j$th observation from simulating solution $x_i$.  typically assume $Y_j (x_i) \sim N(g(x_i), \sigma_i^2 )$, where $g(x_i)$ is unknown and $\sigma_i^2$ either known or unknown.  Without loss of generality, have $g(x_1) \le g(x_2) \le ... \le g(x_k)$
\begin{equation}
P[ \mbox{select } x_k | g(x_1) \le g(x_2) - \delta ] \ge 1 - \alpha
\end{equation}
$\delta > 0$ is an indifference zone (IZ), set as smallest difference that is practically significant

Bechhofer's procedure
Step 1 is to set how many samples to take, $n$, determine $h$ such that $P [ Z_i \le h, i=1,2,...,k-1 ] = 1-\alpha$ and $(Z_1, ..., Z_{k-1})$ has multivariate normal distribution with means 0, variances 1, common pairwise correlations 1/2, then
\begin{equation}
n = \left\lceil \frac{ 2h^2\sigma^2}{\delta^2} \right\rceil
\end{equation}
Step 2 take $n$ observations
Step 3 select solution with lowest sample mean $\overline{Y}_n (x_i)$

If variances are unknown, typicallly two stage procedures
variances unknown and unequal Rinotts procedure (Ronott 1978)
variances unknown and unequal and common random numbers - Nelson and Matejcik (1995)
number of solutions large, do screening step - Nelson et al (2001)

Also sequential procedures

Paulson's procedure
step 1 Let $0 < \lambda < \delta$
\begin{equation}
a = \ln \left( \frac{k-1}{\alpha} \right) \frac{\sigma^2}{\delta - \lambda}
\end{equation}
Let $I = \left\{ x_1, x_2, ..., x_k \right\}$ and $r=0$
Step 2 $r = r+1$, take one observation from each solution in $I$ and calculate $\overline{Y}_r(x_i)$
Step 3 $I_{old} = I$
\begin{equation}
I = \left\{ x_l \in I_{old} | \overline{Y}_r(x_l) \le \min_{i \in I_{old}} \overline{Y}_i(x_i) + \max \left\{ 0, a/r - \lambda \right\} \right\}
\end{equation}
Step 3 when $| I | = 1$, you have solution

fully sequential procedure, unknown and unequal variances, and crn (Kim and Nelson 2001)
non-normal and dependent (Kim and Nelson 2006)
typically require less samples
Hong and Nelson (2005) reduced number of switchings
Branke Chick Schmidt (2007) comprehensive set of experience, no R\&S procedure dominate
Bayesian procedures often more efficient in number of samples
do not provide selection guarantees that frequentist procedures do


Stochastic Approximation and Gradient Estimation

\begin{equation}
x_{n+1} = \prod_\Theta \left[ x_n - a_n \hat{\grad} g(x_n) \right]
\end{equation}
$x_n$ solution at iteration $n$, $\hat\grad g(x_n)$ is estimate of gradient, $\lb a_n \rb$ sequance of positive real numbers called gain sequence, and $\prod_\Theta$ is projection onto feasibly region.

SA alg first proposed by Robbins and Monro (1951) - root finding algorithm
stochastic version of steepest descent algorithm
but gradient in SA is noisy estimate, convergence requires $\Expect \left[ \hat \grad g(x_n) \right] - g(x_n) \rightarrow 0$ at a certain rate
step size is often pre-determined, instead of adaptive
convergence requires $\sum_{n=1}^\infty a_n = \infty$ and $\sum_{n=1}^\infty a_n^2 < \infty$, algorithm sensitive to choice of $\lb a_n \rb$.  $\lb a_n \rb $ too large and $x_n$ oscillatory, $\lb a_n \rb $ too small, $x_n$ barely changes

simulation as black box $\grad g(x)$ by finite difference, use forward estimate with $d+1$ sim evals or central difference with $2d$ sim runs.
when dimension of $x$ large, not efficient due to number of sims required for one gradient evaluation
Spall (1992) proposed simultaneuous pertubation uses 2 sim runs to produce estimate
Spall (1998) gives nice intro to theory and application

When inside structure known, use this to get better gradient estimators
Fu (2008) gives excellent overview, pertubation analysis (PA), likelihood ratio/score function (LR/SF)
PA proposed by Ho and Cao (1983)
\begin{equation}
\grad g(x) = \grad \Expect [ Y(x) ] = \Expect [ \grad Y (x) ] 
\end{equation}
with $Y(x)$ stochastically lipschitz continuous and differentiable with prob 1.
overcome bad properties of $Y(x)$
smoothed pertubabtion analysis Gong and Ho (1987) Fu and Hu (1997)
pathwise method Hong (2009) Hong and Liu (2009)

LR/SF method in Reiman Weiss (1989) Glynn (1990)
represent $Y(x) = h(Z)$, $Z$ is vector of random variables generated in sim and $h(Z)$ is performance measure intereseted in .  $f_z(z,x)$ denote probability density of $Z$.  Note $x$ is only in density function of $Z$ and not $h(\dot)$.
then under some regularity conditoins
\begin{align}
\grad g(x) &= \grad \Expect [ h(Z) ] = \grad \int h(z) f_z(z,x) dz = \int h(z) \grad_x f_z(z,x) dz \\
	&= \Expect [ h(Z) \grad_x \log [ f_z(Z,x) ] ]
\end{align}
if $f_z(z,x)$ is known, then LR SF estimate $\grad g(x)$ by $h(Z) \grad_x \log [ f_z(Z,x) ]$. requires only single simulation run to comput, is unbiased estimaor, and does not require $Y(x)$ to be stochastic lipschitz continuous, applicabiliity often wider than PA, however variance of estimator is often high

Random Search Algorithms



\subsubsection{Variance Reduction}
common random number
reference textbook on simulation Simulation Modeling and Analysis (Averill M. Law) \cite{law_2007}
Dobson splitting method, type of importance sampling

Covariance matrix
try instead of solving economic dispatch, solve min variance problem ??? analogous to CAPM, need to make modifcation though!!!! its all related sooo close


look for a set of net power injects wich minimizes the variance in revenue/cost at all of the nodes, perhaps weighted by centrallity, otherwise weight evenly?
what are characterstics of this set versus the one formed from economic dispatch over day ahead and real time markets
what is difference in cost
what is difference in reliability


%%%%%%%%%%%%%%

\subsubsection{Stochastic Approximation}

Stochastic versions (get stochastic book)
Sample Approximation Average
robust stochastic approximation (Nemirovsky Juditsty, Lan, Shapiro)
Spoll  -Introduction to stochastic search and Optimization
Adaptive Robust optimization for Security Constrained Unit Commitment  (Bertsimas, Lituinov, Sun, Zhao, Zheng)


%%%%%%%%%%%%%%%%%
Lan -  Randomized Stochastic Gradient
stochastic descent
zeroth order function values only
gaussian smoothhing function  (nesterov)

-mirror descent Meirovski 23,18
-sample average approximation 16, 36
-This
-subgradient averaging 13, 15, 26

\begin{equation}
f^* := \inf_{x \in \R{n}} f(x)
\end{equation}
$f: \R{n} \rightarrow \R{}$ differentiable
$\bigtriangledown$ Lipschitz continuous
\begin{equation}
|| \bigtriangledown f(y) - \grad f (x) || \le L || y - x ||
\end{equation}

stochastic gradient
$G (x_k, \xi_k$, $\xi_k$ random variable, distribution $P_k$ supported on $\Xi \subset \R{d}$
with following assumptions, get convergence results that are good
\begin{align}
\Expect \left[ G(x_k,\xi_k) \right] = \grad f (x_k)		\\
\Expect \left[ || G(x_k,\xi_k) - \grad f(x)||^2 \right] \le \sigma^2
\end{align}

get $(\epsilon, \Lambda)$ solution, $\epsilon > 0$, $\Lambda \in (0,1)$
st.
Prob $\left\{ || \grad f(\overline{x}) ||^2 \le \epsilon \right\} \ge 1-\Lambda$
is bounded

%%%%%%%%%%%%%%%%%%%


%\subsubsection{Stochastic Programming}

%%%%%%%%%%%%%%%%%%%%
Stochastic Trust Region	(Chang and Wan) \cite{chang_2009}
\begin{equation}
\min_{x \in \mathbb{X}^p} g(x)
\end{equation}
with $g(x) = \Expect [ G(x,\omega) ]$, 
$G(x, \omega)$ is stochastic response
$\omega$ stochastic effect of system
$x$ is controllable parameter
\begin{equation}
G(x, \omega) = g(x) + \epsilon_x
\end{equation}
$g(x)$ uknown deterministic function
$\epsilon_x$ is random error induced by $\omega$, assume $\epsilon_x \sim F( \dot )$ where 
$F( \dot )$ is a general distribution, mean zero and variance $\sigma_x^2$

Assumptions
$G$ expectation bounded above
$g$ bounded below, twice differentiable, gradient and Hessian uniformly bounded
for a sufficiently small neighborhood, $G$ can be modeled as a quadratic with error $\epsilon_x$ 
--Taylor Teorem (Trench 2003)

Strong Law of Large Numbers
\begin{equation}
\overline{G}_N (x) = \frac{ \sum_{i=1}^N G(x,\omega_i) }{N} \rightarrow g(x) \mbox{    w.p. 1}
\end{equation}
as $N \rightarrow \infty$ for every $x \in \mathbb{X}^p$

Uses 2 stage process
initially, just use first order points
as trust region shrinks, there is transition points
begin to sample more, construct second order model, and reduce trust region at successful iterates

%%%%%%%%%%%%%%%%%%%%%


reference textbook on stochastic programing
Lectures on Stochastic Programing (Shapiro) \cite{shapiro_2009}


Master Problem


