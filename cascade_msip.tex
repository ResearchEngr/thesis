
\chapter{Multi Stage Stochastic Model of Cascading Failures}

\section{Model Overview}
This program can be used to evaluate a set of design scenarios for either transmission line expansion or operating reserves in order to minimize the potential for cascading failures under a set of outage contingencies.
\subsection{Design Parameters}
capacity of lines, capacity of generators, level of operating reserves
\subsection{Strengths of Model}
concurrently analysis against multiple contingencies with respect to cascading failures

\subsection{Model for single contingency}
This is mixed integer formulation for OPA simulation

\subsection{General Model}
Combines multiple contingencies with addition of the design linking variable

\subsection{Objectives}
Greedy objective , others

\section{Modeling Limitations}

We will assume that the blackout occurs in a fixed finite number of
stages, where at each stage the operators have the ability to take
some recourse actions.  Specifically, in order to mitigate the effect
of the blackout, the operators may choose to do
load shedding, reducing the amount of power that a customer
receives, or  generation dispatch, changing the amount of
generation capacity (within limit) at the generation points in the
network. 


In the OPA model, cascades are simulated by
solving a linear program that satisfies the power flow equations and
attempts to minimize the load shed.  Then, once new power flows are
determined, a certain percentage of the lines that are at capacity
fail, and the process repeats until stable.  This simple simulation
process, once calibrated, has been shown to accurately capture the
historical distribution of blackout sizes.

A distinguishing features of the uncertainty in the model is that the
line failures are not completely random, but in a loose sense controlled
by the power flows injected into the network.  This em
  decision-dependent uncertainty is complicates the modeling effort.
In our model, the complication is handled with the addition of binary
variables.




\section{IP Formulation}

\subsection{Sets}

\begin{itemize}
\item $ \cG \equiv $ Generators 
\item $ \cD \equiv $ Demand Nodes 
\item $ \cB \equiv $ Buses 
\item $ \cS \equiv $ Scenarios 
\item $ \cN \equiv $ Nodes of Scenario Tree\\
	$\rho \left( n \right) \equiv $ Predecessor of node $ n \in \cN $
\item $ \cV \equiv $ Vertices $ = \cG \cup \cD \cup \cB $
\item $ \cE \equiv $ Edges, $ \cE \subseteq (\cV{V} \times \cV )$\newline
	$  a = ( i , j )  $,  where the arc has orientation: $(i,j)$ is ordered. 
\item Time stages $\{2,\ldots T\}$ in which the cascade occurs.
\end{itemize}





The underlying random elements in our stochastic process are whether
or not each line will fail as a function of the magnitude of the load
on the line.  Each line $e \in E$ has a (nominal/rated) capacity
$u_e$, but in reality, this line limit may be exceeded, and the
probability of a line failure should be a monotonically increasing
function of the load on the line.

and the power 
flow equations ensure that the flow never exceeds this capacity.  In
our stochastic model, each line $e \in E$ has an {\em effective
  capacity} $R_e(\omega)$ which is the capacity at which the
line will fail under outcome $\omega$.  For example, to implement the
OPA model, where lines fail with probability $p$ if $f_{e} = u_{e}$,
one could set
\[ 
R_e = \begin{cases} 
u_e - \epsilon & \mbox{ with probability } p\\
u_e + \epsilon & \mbox{ with probability } 1-p
\end{cases}
\]
In general, the vectors $(\theta(\omega_2), \ldots \theta(\omega_t))$
are $|E|$-dimensional random vectors that form a stochastic process.
(Sample space is $\Omega = \Omega_2 \times \Omega_3 \times \ldots
\times \Omega_T$).  We suspect that a reasonable assumption is
stagewise indepdence of the random variables $\omega_t$.  Perhaps also
reasonable is independence of $\theta_e(\omega_e) \forall e \in E$.

The stochastic program we present .  It {\em does} have knowledge of
all of the outcomes, the decision made at node $n$ {\em must be the
  same} -- must be obeyed for all child nodes.

This poses a problem for modeling directly the exact OPA distribution,
as it is likely that an optimal solution will be to reduce the load on
each line by epsilon, and thus completely stop the cascade.

More generally, we can consider a cumulative distribution function
$F_e(f_e)$ to define the probability that a line fails as a function of
its load $f_e$.




(We need to talk about the underlying probability space).





\begin{itemize}
\item $G=(V,E)$ is a graph containing the (original?) network topology
\item $\cD \subset V$ is the subset of demand nodes.
\item Time stages $\{2,\ldots T\}$ in which the cascade occurs.
\item Let $N_t$ be the set of nodes in the scenario tree at stage $t \in
\{2, \ldots, T\}$
\item $N = \cup_{t=2}^T N_t$ is the set of nodes in the scenario tree
\item We denote $p_n$ as the (conditional) probability of
the sequence of outcomes leading to node $n$ in the scenario occuring
\item $\rho(n)$ is the predecessor of node $n$ in the scenario tree.
\item $\theta_{en}$ is the effective capacity of edge $e \in E$ at
  node $n \in N$
\end{itemize}




\subsection{Parameters}

\begin{itemize}
\item $X_e \equiv $ Reactance of edge $e \in \cE$
\item $ \overline{P}_i, \underline{P}_i \equiv $ Upper and lower bounds on power produced at $ i \in \cG $
\item $ U_{ij} \equiv$ Nominal Capacity of line $(i,j) \in \cE$
\item $ R_{ijn} \equiv$  Effective capacity of $(i,j) \in \cE$ at node $n \in \cN$
\end{itemize}


\subsection{Variables}

\begin{itemize}
\item $f_{ijn} \equiv $ Flow in direction $(i,j) \in \cE$ at node $ n \in \cN $
\item $p_{in} \equiv $ Power injected at generator $i \in \cG$ at node $n \in \cN$
\item $\theta_{in} \equiv $ Phase angle at vertex $i \in \cV$ at node $n \in \cN$
\item $d_{in} \equiv $ Power delivered at vertex $i \in \cV$ at node $n \in \cN$
\item $z_{ijn} \equiv  
	\left\{ 
	\begin{array}{lr}
			1 & \mbox{if edge } (i,j) \in \cE \mbox{ is available at node } n \in \cN\\
			 0 & \mbox{otherwise}
	\end{array}
	\right.$
\item $y_{in} \equiv  
	\left\{ 
	\begin{array}{lr}
			1 & \mbox{if generator } i \in \cG] \mbox{ is on at node } n \in \cN\\
			 0 & \mbox{otherwise}
	\end{array}
	\right.$
\end{itemize}


\subsection{Model}


$
\begin{array}{cc}

\displaystyle\sum_{(i,j) \in \delta^+(i)}f_{ijn} - \sum_{(i,j) \in \delta^-(i)}{f_{ijn}} \equiv  
	\left\{ 
	\begin{array}{l}
			p_{in} \\
			 -d_{in} \\
			 0
	\end{array}
	\right.  
		&
	\begin{array}{r}
			\forall i \in \cG], \forall n \in \cN \\
			 \forall i \in \cD, \forall n \in \cN \\
			\forall i \in \cB, \forall n \in \cN 
	\end{array}\\

 -M(1-z_{ijn}) \le \theta_{in} - \theta_{jn} + X_{ij} f_{ijn} \le M (1-z_{ijn}) 
	& \forall (i,j) \in \cE, \forall n \in \cN  \\

-U_{ij} z_{ijn} \le f_{ijn} \le U_{ij} z_{ijn} 
	&  \forall (i,j) \in \cE, \forall n \in \cN \\

z_{ijn} \le 1-w_{ijn}  
	&  \forall (i,j) \in \cE, \forall n \in \cN \\

z_{ijn} \le 1 - x_{ijn} 
	&  \forall (i,j) \in \cE, \forall n \in \cN \\

f_{ij\rho(n)} - R_{ijn} \le M x_{ijn} 
	&  \forall (i,j) \in \cE, \forall n \in \cN \backslash \left\{ 1 \right\} \\

f_{ij\rho(n)} + R_{ijn} \ge - M x_{ijn} 
	&  \forall (i,j) \in \cE, \forall n \in \cN \backslash \left\{ 1 \right\} \\

x_{ijn} \ge x_{ij\rho(n)}  
	&  \forall (i,j) \in \cE, \forall n \in \cN \backslash \left\{ 1 \right\} \\

\underline{P_i} y_{in} \le p_{in} \le \overline{P_i} y_{in} 
	&  \forall i \in \cG], \forall n \in \cN \\

\displaystyle \sum_{i \in \cD}{ \sum_{n \in \cN_{t+1} }{ d_{in} } }\le \sum_{i \in \cD}{ \sum_{n \in \cN_t }{ d_{in} } } 
	&  \forall t \in \left\{ 1, ..., T-1 \right\}  \\

x_{ijn}, w_{ijn}, z_{ijn} \in \left\{ 0,1 \right\} 	
	&  \forall  (i,j) \in \cE, \forall n \in \cN \\

y_{in} \in \left\{ 0,1 \right\}
	&  \forall  i \in \cG], \forall n \in \cN \\

d_{in} \ge 0 	
	&  \forall  i \in \cD, \forall n \in \cN 

\end{array}
$


Other stuff




In order to minimize the average total load-shed, for example, an
objective would be to 

\[ \max \sum_{n \in N_T} p_n \sum_{i \in \cD d_{in}} \]

\begin{align}
z_{en} &\leq z_{e\rho(n)} \quad \forall n \in N \setminus \{1\}, 
\forall e \in E \label{eq:deadparent} \\
f_{en} &\leq u_e z_{en} \quad \forall n \in N, \quad
\forall e \in E \label{eq:vub} \\
f_{e\rho(n)} - \theta_{en} &\leq M(1-z_{en}) \quad \forall n \in N
\setminus \{1\},  \forall e \in E \label{eq:burnout}\\
F(p_n,z_n) &= f_n \quad \forall n \in N \label{eq:powerflow}
\end{align}

The equations \eqref{eq:deadparent} model the fact that once a line
burns out, it is out for the remainder of the cascade, \eqref{eq:vub}
enforce no flow on an arc if it has burned out, \eqref{eq:burnout}
models the fact that a child node's arcs will be unavailable if the
parent node's arcs is over the (random) threshold capacity for that
scenario.  Finally, the equations \eqref{eq:powerflow} are the
powerflow equations that determine the flows $f$ as a function of the
power injections $p$ and remaining lines (encoded in $z$.)


\section*{Extensions/To Do/Commentary}

\begin{itemize}
\item We need to decide on a flow model \eqref{eq:powerflow}.  DC is
  probably all we can handle at this point.
\item Line Switching could be added easily
\item Compare against a rolling two stage model?
\item We could even try to model ``recovery'' as starting at a fixed
  stage $T+1$? But it is a hard question to answer, as the number of
  stages $T$ in a real cascade would not be known.
\item Try different (more robust) objectives.   Many different
  objectives (like cVAR, or mean downside blackout size) could be
  incorporated. 
\item This will be a {\em very} hard problem to solve, but maybe with
  some progresive-hedging type heuristics, we can get some reasonable
  solutions. 
\item Another good question is to discuss the generation of a real
  policy.  This is all based on sampling, so it is unclear what the
  solution means.  Perhaps we can copy some of Dan's affine policy
  stuff.  I am thinking that a reasonable policy might be to suggest
  that each generator shed $\alpha\%$ more load than suggested by the
  minimum load shed solution.
\end{itemize}


\section{Power Flow Equations}

%Plagzrized from somewhere on web
A power system is described by using three different types of nodes
and the node interconnections. The three different types of nodes,
which are also referred to as busses, include the $P-Q$ bus, $P-V$ bus,
and the slack bus. The $P-Q$ bus is used to represent a load. The $P-Q$
bus has the total injected complex power specified that includes both
the real power (P) and the reactive power (Q). The P-V bus, which
represents a generator, has the real power (P) and the voltage
magnitude (V) specified. The slack bus, which also represents a
generator, has the voltage magnitude (V) and phase angle (q)
specified. The scope of this project will include systems with one
slack bus and multiple P-Q and P-V busses.



\section{Simulation-Based Optimization}

(These are just some notes for Jeff to keep track of the ideas...)

When dealing with a design of a power grid on a network $N=(V,E)$ to
mitigate the negative impact of a cascading event, the load shed is a
function
\begin{equation}
\label{eq:f}
F(x,\xi,D,\omega)
\end{equation}
of a number of different types of variables:
\begin{itemize}
\item $x \in \mathbb{R}^{|E|}_+$ is the additional capacity to be
  added to the lines in the network.  We will assume that we have a
  budget constraint of the form;
\[ X = \{x \in \mathbb{Z}^{|E|}_+ \ | \ a^Tx \leq b \} \]
\item $\xi \in \Xi$ is a (random) variable modeling the initial
  (triggering) event of the cascade.  We will typically assume that
  $\xi$ models a small number of lines being removed from the
  network. 
\item $D$ is a random variable modeling the demands at the nodes of
  the network 
\item $\omega$ is a random variable modeling how the cascade event
  unfolds.   This is done via simulation---an 'open-loop' OPA
  procedure---requiring the solution of a sequence of linear
  programs. 
\end{itemize}


Our goal is to design the network to minimize the likelihood of a
major blackout in the case of a 'major' initial event. 
Specifically, let 
\[ G_\kappa(x,\xi) = \Prob_{D,\omega} [F(x,\xi,D,\omega) > \kappa] \]
be the probability that the blackout size exceed $\kappa$ if the
initial line capacities are bolstered by an amount $x$ and the initial
event $\xi \in \Xi$ occurs.   In this context, it likely makes sense
to be ``robust'' with respect to line failure events, so we are
interested in the worst case function
\[ H(x) = \max_{\xi \in \Xi} G(x,\xi), \]
which gives the  probability that the blackout size exceed $\kappa$ in
the worst case if line capacities of $x$ are added to the network. 
With this notation, our optimization problem, is then to 
\[ \min_{x \in X} H(x) \]

\begin{itemize}
\item The aggregating function of the blackout size random variable
$\Prob_{D,\omega}(\cdot)$ (with respect to random demands and cascade
evolution) may 
later be replaced with a measure such as Average (or Conditional)
Value at Risk.
\end{itemize}


\subsection{Recent Ideas}

\begin{itemize}
\item Is it possible to use some of the ideas of Roger Wets on
  estimating densities of random variables based on only a few
  observations (and additional shape information about the variable).
  The trouble is that we have one random variable for each $x$, $D$,
  and $\xi$ so estimation only one may not help our design problem.
  It would be great if we could build some sort of surrogate for
  optimization. 
\item We could possibly try and do importance sampling in the
  following way: At OPA round $r$, suppose that there are $K_r$ lines
  at capacity, which implies that the expcted number of filed lines is
  $\alpha K_r$. 
\begin{itemize}
\item This gives a simple ideas to do variance reduction: using Latin
  Hypercube for example
\item We could also do imoprtance sampling, since if $X_r$ is a random
  variable for the number of lines failing at round $r$, then $X \sim
  \mbox{ Bernoulli}(K_r, \alpha)$ and we can compute the probability
  of more lines failing and thus get an unbiased estimate using
  importance sampling
\end{itemize}
\end{itemize}

\subsection{Notes from April 18}

An important question to answer from a modeling perspective is what is
a relevant statistic to try to optimize.  One suggestion from Ian
Dobson was to 
\[ \min_{x \in X} \Prob_{D,\xi,\omega} [F(x,\xi,D,\omega) \geq
  \tau], \]
where $\tau$ is something like 5\% of the total demand.

Another simple idea is to minimize the expected value, as is common in
stochastic programming:
\[ \min_{x \in X} \Expect_{D,\xi,\omega} [F(x,\xi,D,\omega)]. \]

Perhaps the best measure is the robust measure
\[ \min_{x \in X} \Prob_{D,\omega} \left[ \max_{\xi \in \Xi}
  F(x,\xi,D,\omega) \geq \tau \right], \]
where $\Xi$ is a set of all possible bad ``contingencies'' that the
policy-maker wishes to include.  If $|\Xi|$ is of moderate size,
evaluating 
\[ W(x,D,\omega) \defeq \max_{\xi \in \Xi} F(x,\xi,D,\omega) \]
may be done by enumeration.
In fact, if $|\Xi|$ is small, many interesting statistics could be
computed.  For example:
\[ \min_{x \in X} \Prob_{D, \omega} \left[ \cvar_{\xi,0.95}
  (F(x,\xi,D,\omega) \geq \tau) \right], \]
where $\cvar_{\xi,0.95} (F(x,\xi,D,\omega)$ is the weighted average of
the $5\%$ of the worst cases.

It seems as if regardless of our approach, it may be very useful to
read and understand the seminal works by Calafirori and Campi and
Luedtke on the topic of SAA for chance constraints.


\subsection{Evaluating a Design}
We also talked about how to evaluate a final design $x^*$.  Some ideas:

\begin{itemize}
\item Resample: use our OPA with DC/power flow
\item Resample: use OPA with with AC power flow
\item Change OPA parameter $\alpha$
\item Other software tools?  Other models for cascading?
\end{itemize}

\subsection{Optimizing a Design}
Finally, we need to understand how to do optimization in this context

\begin{itemize}
\item The (Nonconvex) robust optimization paper of Bertsimas {\it et
  al.} should be useful
\item We have some ideas about how to do importance sampling.  We will
  understand the importance of importance samploing once Eric does
  some computational experiments to estimate statistics of the
  blackout function
\item We like the idea of trying to create a surrogate model to
  suggest the next iterate.  Ian's work on estimating the mean
  propagation rate $\mu$ would be useful, but we (likely) need to
  estimate this constant as a function of $\mu(x,D)$ the design and
  the initial load.
\end{itemize}



